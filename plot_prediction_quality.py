#!/usr/bin/env python3
"""
é¢„æµ‹è´¨é‡è¯¦ç»†åˆ†æå›¾

ç”Ÿæˆå¤šç§é¢„æµ‹è´¨é‡å¯è§†åŒ–ï¼š
1. æ—¶åºå¯¹æ¯”å›¾ï¼ˆé¢„æµ‹ vs çœŸå€¼ï¼‰
2. è¯¯å·®åˆ†å¸ƒç›´æ–¹å›¾
3. æ•£ç‚¹å›¾ï¼ˆé¢„æµ‹ vs çœŸå€¼ï¼‰
4. å—è¯•è€…ç›¸å…³æ€§åˆ†å¸ƒ
5. æ—¶é—´çª—å£è´¨é‡åˆ†æ
"""

import os
import json
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
from pathlib import Path
import argparse


def load_test_results(json_path):
    """
    åŠ è½½test_results.json

    Returns:
        dict with keys:
            - model_name: æ¨¡å‹åç§°
            - per_subject: æ¯ä¸ªå—è¯•è€…çš„ç»Ÿè®¡ä¿¡æ¯
            - per_sample: æ¯ä¸ªæ ·æœ¬çš„è¯¦ç»†ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
    """
    with open(json_path, 'r') as f:
        data = json.load(f)

    model_name = data.get('checkpoint', 'Unknown')
    per_subject = data.get('per_subject', [])
    per_sample = data.get('per_sample', [])

    return {
        'model_name': model_name,
        'per_subject': per_subject,
        'per_sample': per_sample
    }


def plot_time_series_comparison(per_sample, output_dir='prediction_analysis',
                                 n_samples=5, sample_indices=None, figsize=(16, 10)):
    """
    ç»˜åˆ¶æ—¶åºå¯¹æ¯”å›¾ï¼ˆé¢„æµ‹ vs çœŸå€¼ï¼‰

    Args:
        per_sample: æ ·æœ¬çº§åˆ«çš„é¢„æµ‹ç»“æœ
        n_samples: æ˜¾ç¤ºå¤šå°‘ä¸ªæ ·æœ¬
        sample_indices: æŒ‡å®šæ˜¾ç¤ºå“ªäº›æ ·æœ¬ï¼ˆNoneåˆ™éšæœºé€‰æ‹©ï¼‰
    """
    os.makedirs(output_dir, exist_ok=True)

    if not per_sample or 'predictions' not in per_sample[0]:
        print("âš ï¸  è­¦å‘Š: æ•°æ®ä¸­æ²¡æœ‰predictionså­—æ®µï¼Œè·³è¿‡æ—¶åºå¯¹æ¯”å›¾")
        return

    # é€‰æ‹©æ ·æœ¬
    if sample_indices is None:
        # éšæœºé€‰æ‹©n_samplesä¸ªæ ·æœ¬
        if len(per_sample) <= n_samples:
            sample_indices = list(range(len(per_sample)))
        else:
            np.random.seed(42)
            sample_indices = np.random.choice(len(per_sample), n_samples, replace=False)
            sample_indices = sorted(sample_indices)

    n_rows = len(sample_indices)
    fig, axes = plt.subplots(n_rows, 1, figsize=figsize, sharex=False)

    if n_rows == 1:
        axes = [axes]

    for idx, sample_idx in enumerate(sample_indices):
        sample = per_sample[sample_idx]

        predictions = np.array(sample['predictions'])
        targets = np.array(sample['targets'])
        pearson_r = sample['pearson']
        subject_id = sample.get('subject_id', 'Unknown')

        time_steps = np.arange(len(predictions))

        ax = axes[idx]

        # ç»˜åˆ¶çœŸå€¼å’Œé¢„æµ‹
        ax.plot(time_steps, targets, label='Ground Truth',
                color='#2E86DE', linewidth=1.5, alpha=0.8)
        ax.plot(time_steps, predictions, label='Prediction',
                color='#EE5A6F', linewidth=1.5, alpha=0.8)

        # æ ‡é¢˜å’Œæ ‡ç­¾
        ax.set_title(f'Subject {subject_id} | Sample {sample_idx} | Pearson r = {pearson_r:.3f}',
                    fontsize=12, fontweight='bold')
        ax.set_ylabel('Speech Envelope', fontsize=10)
        ax.legend(loc='upper right', fontsize=9)
        ax.grid(True, alpha=0.3, linestyle='--')

    axes[-1].set_xlabel('Time Steps', fontsize=11)

    plt.tight_layout()

    output_path = os.path.join(output_dir, 'time_series_comparison.png')
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"âœ“ æ—¶åºå¯¹æ¯”å›¾å·²ä¿å­˜: {output_path}")
    plt.close()


def plot_error_distribution(per_sample, output_dir='prediction_analysis', figsize=(14, 6)):
    """
    ç»˜åˆ¶è¯¯å·®åˆ†å¸ƒç›´æ–¹å›¾å’Œç»Ÿè®¡ä¿¡æ¯
    """
    os.makedirs(output_dir, exist_ok=True)

    if not per_sample or 'predictions' not in per_sample[0]:
        print("âš ï¸  è­¦å‘Š: æ•°æ®ä¸­æ²¡æœ‰predictionså­—æ®µï¼Œè·³è¿‡è¯¯å·®åˆ†å¸ƒå›¾")
        return

    # æ”¶é›†æ‰€æœ‰è¯¯å·®
    all_errors = []
    for sample in per_sample:
        predictions = np.array(sample['predictions'])
        targets = np.array(sample['targets'])
        errors = predictions - targets
        all_errors.extend(errors)

    all_errors = np.array(all_errors)

    # åˆ›å»ºå›¾è¡¨
    fig, axes = plt.subplots(1, 2, figsize=figsize)

    # å·¦å›¾ï¼šè¯¯å·®åˆ†å¸ƒç›´æ–¹å›¾
    ax1 = axes[0]
    n, bins, patches = ax1.hist(all_errors, bins=100, density=True,
                                 color='#3498DB', alpha=0.7, edgecolor='black')

    # æ‹Ÿåˆæ­£æ€åˆ†å¸ƒ
    mu, sigma = all_errors.mean(), all_errors.std()
    x = np.linspace(all_errors.min(), all_errors.max(), 100)
    ax1.plot(x, stats.norm.pdf(x, mu, sigma), 'r-', linewidth=2,
            label=f'Normal fit\nÎ¼={mu:.4f}, Ïƒ={sigma:.4f}')

    ax1.set_xlabel('Prediction Error (Pred - True)', fontsize=12)
    ax1.set_ylabel('Density', fontsize=12)
    ax1.set_title('Error Distribution', fontsize=14, fontweight='bold')
    ax1.legend(fontsize=10)
    ax1.grid(True, alpha=0.3)

    # å³å›¾ï¼šQ-Qå›¾ï¼ˆæ£€éªŒæ­£æ€æ€§ï¼‰
    ax2 = axes[1]
    stats.probplot(all_errors, dist="norm", plot=ax2)
    ax2.set_title('Q-Q Plot (Normality Test)', fontsize=14, fontweight='bold')
    ax2.grid(True, alpha=0.3)

    # ç»Ÿè®¡ä¿¡æ¯
    textstr = '\n'.join([
        f'Mean: {mu:.4f}',
        f'Std: {sigma:.4f}',
        f'Median: {np.median(all_errors):.4f}',
        f'MAE: {np.abs(all_errors).mean():.4f}',
        f'RMSE: {np.sqrt((all_errors**2).mean()):.4f}'
    ])

    ax1.text(0.98, 0.98, textstr, transform=ax1.transAxes,
            fontsize=10, verticalalignment='top', horizontalalignment='right',
            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

    plt.tight_layout()

    output_path = os.path.join(output_dir, 'error_distribution.png')
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"âœ“ è¯¯å·®åˆ†å¸ƒå›¾å·²ä¿å­˜: {output_path}")
    plt.close()


def plot_prediction_scatter(per_sample, output_dir='prediction_analysis',
                            n_samples_max=500, figsize=(10, 10)):
    """
    ç»˜åˆ¶é¢„æµ‹ vs çœŸå€¼æ•£ç‚¹å›¾
    """
    os.makedirs(output_dir, exist_ok=True)

    if not per_sample or 'predictions' not in per_sample[0]:
        print("âš ï¸  è­¦å‘Š: æ•°æ®ä¸­æ²¡æœ‰predictionså­—æ®µï¼Œè·³è¿‡æ•£ç‚¹å›¾")
        return

    # æ”¶é›†æ•°æ®ï¼ˆé™åˆ¶æ ·æœ¬æ•°é¿å…è¿‡å¯†ï¼‰
    all_predictions = []
    all_targets = []

    for sample in per_sample[:n_samples_max]:
        predictions = np.array(sample['predictions'])
        targets = np.array(sample['targets'])
        all_predictions.extend(predictions)
        all_targets.extend(targets)

    all_predictions = np.array(all_predictions)
    all_targets = np.array(all_targets)

    # ç»˜åˆ¶æ•£ç‚¹å›¾
    fig, ax = plt.subplots(figsize=figsize)

    # ä½¿ç”¨hexbinå¤„ç†å¯†é›†ç‚¹
    hexbin = ax.hexbin(all_targets, all_predictions, gridsize=50, cmap='YlOrRd',
                       mincnt=1, alpha=0.8)

    # æ·»åŠ å¯¹è§’çº¿ï¼ˆå®Œç¾é¢„æµ‹çº¿ï¼‰
    min_val = min(all_targets.min(), all_predictions.min())
    max_val = max(all_targets.max(), all_predictions.max())
    ax.plot([min_val, max_val], [min_val, max_val], 'b--', linewidth=2,
           label='Perfect Prediction', alpha=0.7)

    # è®¡ç®—æ•´ä½“Pearsonç›¸å…³ç³»æ•°
    r, p_val = stats.pearsonr(all_targets, all_predictions)

    # çº¿æ€§æ‹Ÿåˆ
    z = np.polyfit(all_targets, all_predictions, 1)
    p = np.poly1d(z)
    ax.plot([min_val, max_val], [p(min_val), p(max_val)], 'r-', linewidth=2,
           label=f'Linear Fit: y={z[0]:.3f}x+{z[1]:.3f}', alpha=0.7)

    ax.set_xlabel('Ground Truth', fontsize=13, fontweight='bold')
    ax.set_ylabel('Prediction', fontsize=13, fontweight='bold')
    ax.set_title(f'Prediction vs Ground Truth\nPearson r = {r:.4f} (p < {p_val:.2e})',
                fontsize=15, fontweight='bold')
    ax.legend(fontsize=11)
    ax.grid(True, alpha=0.3)

    # æ·»åŠ colorbar
    cbar = plt.colorbar(hexbin, ax=ax)
    cbar.set_label('Count', fontsize=11)

    # ä¿æŒæ­£æ–¹å½¢æ¯”ä¾‹
    ax.set_aspect('equal', adjustable='box')

    plt.tight_layout()

    output_path = os.path.join(output_dir, 'prediction_scatter.png')
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"âœ“ é¢„æµ‹æ•£ç‚¹å›¾å·²ä¿å­˜: {output_path}")
    plt.close()


def plot_subject_correlation_distribution(per_subject, output_dir='prediction_analysis',
                                          figsize=(14, 8)):
    """
    ç»˜åˆ¶å—è¯•è€…ç›¸å…³æ€§åˆ†å¸ƒï¼ˆç›´æ–¹å›¾ + ç®±çº¿å›¾ï¼‰- åªåˆ†æå—è¯•è€…1-71
    """
    os.makedirs(output_dir, exist_ok=True)

    if not per_subject:
        print("âš ï¸  è­¦å‘Š: æ²¡æœ‰per_subjectæ•°æ®ï¼Œè·³è¿‡å—è¯•è€…åˆ†æ")
        return

    # æå–æ•°æ®ï¼ˆåªä¿ç•™å—è¯•è€…1-71ï¼‰
    subject_ids = [s['subject_id'] for s in per_subject if 1 <= s['subject_id'] <= 71]
    pearsons = [s['avg_pearson'] for s in per_subject if 1 <= s['subject_id'] <= 71]

    # åˆ›å»ºç»„åˆå›¾
    fig = plt.figure(figsize=figsize)
    gs = fig.add_gridspec(2, 2, height_ratios=[2, 1], width_ratios=[2, 1],
                          hspace=0.3, wspace=0.3)

    # å·¦ä¸Šï¼šæ¯ä¸ªå—è¯•è€…çš„Pearsonæ¡å½¢å›¾
    ax1 = fig.add_subplot(gs[0, 0])
    colors = ['#2E86DE' if p >= np.median(pearsons) else '#E74C3C' for p in pearsons]
    bars = ax1.bar(range(len(subject_ids)), pearsons, color=colors, alpha=0.7,
                   edgecolor='black', linewidth=0.5)
    ax1.axhline(y=np.mean(pearsons), color='green', linestyle='--', linewidth=2,
               label=f'Mean: {np.mean(pearsons):.4f}')
    ax1.axhline(y=np.median(pearsons), color='orange', linestyle='--', linewidth=2,
               label=f'Median: {np.median(pearsons):.4f}')
    ax1.set_xlabel('Subject ID', fontsize=11)
    ax1.set_ylabel('Pearson Correlation', fontsize=11)
    ax1.set_title('Per-Subject Performance', fontsize=13, fontweight='bold')
    ax1.legend(fontsize=9)
    ax1.grid(True, alpha=0.3, axis='y')

    # è®¾ç½®xè½´æ ‡ç­¾ï¼ˆæ¯éš”5ä¸ªæ˜¾ç¤ºï¼‰
    tick_positions = range(0, len(subject_ids), max(1, len(subject_ids) // 20))
    tick_labels = [subject_ids[i] for i in tick_positions]
    ax1.set_xticks(tick_positions)
    ax1.set_xticklabels(tick_labels, rotation=45, ha='right')

    # å³ä¸Šï¼šPearsonåˆ†å¸ƒç›´æ–¹å›¾
    ax2 = fig.add_subplot(gs[0, 1])
    ax2.hist(pearsons, bins=20, orientation='horizontal', color='#3498DB',
            alpha=0.7, edgecolor='black')
    ax2.axhline(y=np.mean(pearsons), color='green', linestyle='--', linewidth=2)
    ax2.axhline(y=np.median(pearsons), color='orange', linestyle='--', linewidth=2)
    ax2.set_ylabel('Pearson Correlation', fontsize=11)
    ax2.set_xlabel('Count', fontsize=11)
    ax2.set_title('Distribution', fontsize=13, fontweight='bold')
    ax2.grid(True, alpha=0.3, axis='y')

    # ä¸‹æ–¹ï¼šç®±çº¿å›¾
    ax3 = fig.add_subplot(gs[1, :])
    bp = ax3.boxplot([pearsons], vert=False, patch_artist=True,
                     showmeans=True,
                     meanprops=dict(marker='D', markerfacecolor='red', markersize=10),
                     medianprops=dict(color='darkblue', linewidth=2))
    bp['boxes'][0].set_facecolor('#AED6F1')
    ax3.set_xlabel('Pearson Correlation', fontsize=11)
    ax3.set_title('Summary Statistics', fontsize=13, fontweight='bold')
    ax3.grid(True, alpha=0.3, axis='x')

    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
    textstr = '\n'.join([
        f'N subjects: {len(pearsons)}',
        f'Mean: {np.mean(pearsons):.4f}',
        f'Std: {np.std(pearsons):.4f}',
        f'Median: {np.median(pearsons):.4f}',
        f'Min: {np.min(pearsons):.4f}',
        f'Max: {np.max(pearsons):.4f}',
        f'Q1: {np.percentile(pearsons, 25):.4f}',
        f'Q3: {np.percentile(pearsons, 75):.4f}'
    ])

    ax3.text(0.98, 0.98, textstr, transform=ax3.transAxes,
            fontsize=9, verticalalignment='top', horizontalalignment='right',
            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))

    plt.tight_layout()

    output_path = os.path.join(output_dir, 'subject_correlation_distribution.png')
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"âœ“ å—è¯•è€…ç›¸å…³æ€§åˆ†å¸ƒå›¾å·²ä¿å­˜: {output_path}")
    plt.close()


def plot_correlation_by_performance_group(per_subject, output_dir='prediction_analysis',
                                          figsize=(12, 6)):
    """
    æŒ‰æ€§èƒ½åˆ†ç»„åˆ†æï¼ˆé«˜/ä¸­/ä½æ€§èƒ½å—è¯•è€…ï¼‰- åªåˆ†æå—è¯•è€…1-71
    """
    os.makedirs(output_dir, exist_ok=True)

    if not per_subject:
        print("âš ï¸  è­¦å‘Š: æ²¡æœ‰per_subjectæ•°æ®ï¼Œè·³è¿‡åˆ†ç»„åˆ†æ")
        return

    # åªä¿ç•™å—è¯•è€…1-71
    pearsons = np.array([s['avg_pearson'] for s in per_subject if 1 <= s['subject_id'] <= 71])

    # æŒ‰ä¸‰åˆ†ä½æ•°åˆ†ç»„
    q33 = np.percentile(pearsons, 33.33)
    q67 = np.percentile(pearsons, 66.67)

    low_group = pearsons[pearsons <= q33]
    mid_group = pearsons[(pearsons > q33) & (pearsons <= q67)]
    high_group = pearsons[pearsons > q67]

    # ç»˜åˆ¶åˆ†ç»„å¯¹æ¯”
    fig, axes = plt.subplots(1, 2, figsize=figsize)

    # å·¦å›¾ï¼šå°æç´å›¾
    ax1 = axes[0]
    data_to_plot = [low_group, mid_group, high_group]
    parts = ax1.violinplot(data_to_plot, positions=[1, 2, 3], showmeans=True, showmedians=True)

    for pc in parts['bodies']:
        pc.set_facecolor('#3498DB')
        pc.set_alpha(0.7)

    ax1.set_xticks([1, 2, 3])
    ax1.set_xticklabels(['Low\n(Bottom 33%)', 'Mid\n(Middle 33%)', 'High\n(Top 33%)'])
    ax1.set_ylabel('Pearson Correlation', fontsize=12)
    ax1.set_title('Performance Distribution by Group', fontsize=13, fontweight='bold')
    ax1.grid(True, alpha=0.3, axis='y')

    # å³å›¾ï¼šç»Ÿè®¡è¡¨æ ¼
    ax2 = axes[1]
    ax2.axis('off')

    table_data = [
        ['Group', 'N', 'Mean', 'Std', 'Range'],
        ['Low', len(low_group), f'{low_group.mean():.4f}', f'{low_group.std():.4f}',
         f'{low_group.min():.3f}-{low_group.max():.3f}'],
        ['Mid', len(mid_group), f'{mid_group.mean():.4f}', f'{mid_group.std():.4f}',
         f'{mid_group.min():.3f}-{mid_group.max():.3f}'],
        ['High', len(high_group), f'{high_group.mean():.4f}', f'{high_group.std():.4f}',
         f'{high_group.min():.3f}-{high_group.max():.3f}']
    ]

    table = ax2.table(cellText=table_data, cellLoc='center', loc='center',
                     colWidths=[0.2, 0.15, 0.2, 0.2, 0.25])
    table.auto_set_font_size(False)
    table.set_fontsize(10)
    table.scale(1, 2)

    # è¡¨å¤´æ ·å¼
    for i in range(5):
        table[(0, i)].set_facecolor('#4472C4')
        table[(0, i)].set_text_props(weight='bold', color='white')

    # æ•°æ®è¡Œæ ·å¼
    for i in range(1, 4):
        for j in range(5):
            table[(i, j)].set_facecolor('#E7E6E6' if i % 2 == 0 else 'white')

    ax2.set_title('Group Statistics', fontsize=13, fontweight='bold', pad=20)

    plt.tight_layout()

    output_path = os.path.join(output_dir, 'performance_groups.png')
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"âœ“ æ€§èƒ½åˆ†ç»„åˆ†æå›¾å·²ä¿å­˜: {output_path}")
    plt.close()


def generate_all_plots(json_path, output_dir='prediction_analysis'):
    """
    ç”Ÿæˆæ‰€æœ‰é¢„æµ‹è´¨é‡åˆ†æå›¾
    """
    print(f"\n{'='*80}")
    print(f"é¢„æµ‹è´¨é‡åˆ†æ")
    print(f"{'='*80}\n")

    print(f"ğŸ“‚ åŠ è½½æµ‹è¯•ç»“æœ: {json_path}")

    if not os.path.exists(json_path):
        print(f"âŒ é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ {json_path}")
        return

    # åŠ è½½æ•°æ®
    results = load_test_results(json_path)
    model_name = results['model_name']
    per_subject = results['per_subject']
    per_sample = results['per_sample']

    print(f"âœ“ æ¨¡å‹: {model_name}")
    print(f"âœ“ å—è¯•è€…æ•°: {len(per_subject)}")
    print(f"âœ“ æ ·æœ¬æ•°: {len(per_sample)}")

    print(f"\n{'='*80}")
    print("ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
    print(f"{'='*80}\n")

    # 1. æ—¶åºå¯¹æ¯”å›¾
    if per_sample:
        print("[1/5] ç”Ÿæˆæ—¶åºå¯¹æ¯”å›¾...")
        plot_time_series_comparison(per_sample, output_dir, n_samples=5)

    # 2. è¯¯å·®åˆ†å¸ƒå›¾
    if per_sample:
        print("[2/5] ç”Ÿæˆè¯¯å·®åˆ†å¸ƒå›¾...")
        plot_error_distribution(per_sample, output_dir)

    # 3. é¢„æµ‹æ•£ç‚¹å›¾
    if per_sample:
        print("[3/5] ç”Ÿæˆé¢„æµ‹æ•£ç‚¹å›¾...")
        plot_prediction_scatter(per_sample, output_dir)

    # 4. å—è¯•è€…ç›¸å…³æ€§åˆ†å¸ƒ
    if per_subject:
        print("[4/4] ç”Ÿæˆå—è¯•è€…ç›¸å…³æ€§åˆ†å¸ƒå›¾...")
        plot_subject_correlation_distribution(per_subject, output_dir)

    print(f"\n{'='*80}")
    print(f"âœ“ æ‰€æœ‰å›¾è¡¨å·²ç”Ÿæˆå®Œæˆï¼")
    print(f"  è¾“å‡ºç›®å½•: {output_dir}/")
    print(f"{'='*80}\n")


def main():
    parser = argparse.ArgumentParser(
        description='é¢„æµ‹è´¨é‡è¯¦ç»†åˆ†æ - ç”Ÿæˆå¤šç§å¯è§†åŒ–å›¾è¡¨',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # ä½¿ç”¨é»˜è®¤è·¯å¾„
  python plot_prediction_quality.py

  # æŒ‡å®štest_results.jsonè·¯å¾„
  python plot_prediction_quality.py --json_path path/to/test_results.json

  # æŒ‡å®šè¾“å‡ºç›®å½•
  python plot_prediction_quality.py --output_dir my_analysis
"""
    )

    parser.add_argument('--json_path', type=str,
                       default='/RAID5/projects/likeyang/happy/NeuroConformer/test_results_eval/conformer_v2_nlayer4_dmodel256_nhead4_gscale1.0_dist_20251216_000230_best_model/test_results.json',
                       help='test_results.jsonæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output_dir', type=str,
                       default='prediction_analysis',
                       help='è¾“å‡ºç›®å½•')

    args = parser.parse_args()

    generate_all_plots(args.json_path, args.output_dir)


if __name__ == '__main__':
    main()
