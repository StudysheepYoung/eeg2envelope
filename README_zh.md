# HappyQuokka: EEG-to-Speech è§£ç ç³»ç»Ÿ

<p align="center">
  <img src="HappyQuokka.png" width="60%" alt="HappyQuokka Logo">
</p>

<p align="center">
  <strong>ICASSP 2023 å¬è§‰è„‘ç”µå›¾æŒ‘æˆ˜èµ›ä»»åŠ¡2ï¼ˆå›å½’ï¼‰çš„å®˜æ–¹PyTorchå®ç°</strong>
</p>

---

## ğŸ“– é¡¹ç›®æ¦‚è¿°

HappyQuokka æ˜¯ä¸€ä¸ªåŸºäºæ·±åº¦å­¦ä¹ çš„ EEG-to-Speech è§£ç ç³»ç»Ÿï¼Œèƒ½å¤Ÿä»å¤šé€šé“è„‘ç”µå›¾ï¼ˆEEGï¼‰ä¿¡å·ä¸­é‡å»ºè¯­éŸ³åŒ…ç»œã€‚è¯¥é¡¹ç›®å‚åŠ äº† ICASSP 2023 å¬è§‰è„‘ç”µå›¾æŒ‘æˆ˜èµ›ï¼Œä¸“æ³¨äºä»ç¥ç»ä¿¡å·ä¸­è§£ç è¯­éŸ³ä¿¡æ¯çš„å›å½’ä»»åŠ¡ã€‚

### ğŸ¯ æ ¸å¿ƒä»»åŠ¡
- **è¾“å…¥**: 64é€šé“EEGä¿¡å· (10ç§’@64Hzé‡‡æ ·ç‡)
- **è¾“å‡º**: é‡å»ºçš„è¯­éŸ³åŒ…ç»œä¿¡å·
- **ç›®æ ‡**: å®ç°é«˜ç²¾åº¦çš„ç¥ç»ä¿¡å·åˆ°è¯­éŸ³ä¿¡å·çš„è§£ç 

### ğŸ—ï¸ æ¨¡å‹æ¶æ„

æˆ‘ä»¬çš„ç³»ç»Ÿé‡‡ç”¨ **CNN + Transformer æ··åˆæ¶æ„**ï¼Œç»“åˆäº†ç©ºé—´ç‰¹å¾æå–å’Œæ—¶åºå»ºæ¨¡ï¼š

```
EEG [64Ã—640] â†’ CNNç‰¹å¾æå– â†’ é€šé“æ³¨æ„åŠ› â†’ å—è¯•è€…æ¡ä»¶åŒ– â†’
Transformerç¼–ç  â†’ çº¿æ€§è¾“å‡º â†’ è¯­éŸ³åŒ…ç»œ [1Ã—640]
```

<p align="center">
  <img src="model_architecture_with_data.png" width="90%" alt="æ¨¡å‹æ¶æ„å›¾">
</p>

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

```bash
# Python ç¯å¢ƒ
Python >= 3.8
PyTorch >= 1.8.0
CUDA >= 11.0 (æ¨èGPUè®­ç»ƒ)

# ä¸»è¦ä¾èµ–
torch
numpy
matplotlib
scipy
```

### å®‰è£…

```bash
git clone https://github.com/your-username/HappyQuokka_system_for_EEG_Challenge.git
cd HappyQuokka_system_for_EEG_Challenge

# å®‰è£…ä¾èµ–
pip install torch numpy matplotlib scipy
```

### æ•°æ®å‡†å¤‡

1. ä¸‹è½½ [EEG æ•°æ®é›†](https://rdr.kuleuven.be/dataset.xhtml?persistentId=doi:10.48804/K3VSND)
2. è§£å‹ `split_data.zip` åˆ° `data/` ç›®å½•ï¼š

```
data/
â”œâ”€â”€ split_data/
â”‚   â”œâ”€â”€ train_-_*
â”‚   â”œâ”€â”€ val_-_*
â”‚   â””â”€â”€ test_-_*
```

### è®­ç»ƒæ¨¡å‹

**å•GPUè®­ç»ƒï¼š**
```bash
python train_v10_sota.py --experiment_folder my_experiment
```

**å¤šGPUåˆ†å¸ƒå¼è®­ç»ƒï¼š**
```bash
# ä½¿ç”¨ DDP
python -m torch.distributed.launch --nproc_per_node=4 train_v10_sota.py --use_ddp --experiment_folder my_experiment_ddp

# æˆ–ä½¿ç”¨æˆ‘ä»¬çš„åˆ†å¸ƒå¼è„šæœ¬
python run_ddp.py
```

### å…³é”®å‚æ•°

```bash
python train_v10_sota.py \
    --epoch 1000 \               # è®­ç»ƒè½®æ•°
    --batch_size 64 \            # æ‰¹æ¬¡å¤§å°
    --learning_rate 0.0001 \     # å­¦ä¹ ç‡
    --win_len 10 \               # çª—å£é•¿åº¦(ç§’)
    --n_layers 8 \               # Transformerå±‚æ•°
    --d_model 256 \              # æ¨¡å‹ç»´åº¦
    --n_head 4 \                 # æ³¨æ„åŠ›å¤´æ•°
    --dropout 0.3 \              # Dropoutç‡
    --g_con True \               # æ˜¯å¦ä½¿ç”¨å…¨å±€æ¡ä»¶å™¨(å—è¯•è€…ID)
    --dataset_folder /path/to/data
```

## ğŸ”§ æ¨¡å‹è¯¦è§£

### æ ¸å¿ƒç»„ä»¶

1. **CNNç‰¹å¾æå–å™¨**
   - ä¸‰å±‚1Då·ç§¯ (kernel: 7â†’5â†’3)
   - LayerNorm + LeakyReLU + Dropout
   - 64é€šé“ â†’ 256ç»´ç‰¹å¾

2. **SEé€šé“æ³¨æ„åŠ›**
   - Squeeze-and-Excitationæœºåˆ¶
   - è‡ªé€‚åº”é€šé“æƒé‡

3. **å…¨å±€æ¡ä»¶å™¨**
   - å—è¯•è€…IDåµŒå…¥ (One-hot[71] â†’ Linear[256])
   - æ”¯æŒè·¨è¢«è¯•æ³›åŒ–

4. **Transformerç¼–ç å™¨**
   - 8å±‚ PreLNFFTBlock
   - å¤šå¤´è‡ªæ³¨æ„åŠ› (4å¤´Ã—64ç»´)
   - ä½ç½®ç¼–ç 

5. **è¾“å‡ºå±‚**
   - çº¿æ€§æ˜ å°„ (256â†’1ç»´)
   - è¯­éŸ³åŒ…ç»œé‡å»º

### æŸå¤±å‡½æ•°

```python
loss = MSE_loss + Î» Ã— (Pearson_loss)Â²
```

- **MSE**: ç¡®ä¿å¹…å€¼å‡†ç¡®æ€§
- **Pearson**: ç¡®ä¿æ³¢å½¢ç›¸å…³æ€§
- **Î»=1.0**: å¹³è¡¡ä¸¤ä¸ªæŸå¤±é¡¹

## ğŸ“Š å®éªŒç»“æœ

### è®­ç»ƒç›‘æ§

æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šè‡ªåŠ¨ç”Ÿæˆï¼š
- TensorBoardæ—¥å¿— (`test_results/experiment_name/`)
- å¯è§†åŒ–å›¾è¡¨ (çœŸå®vsé‡å»ºåŒ…ç»œå¯¹æ¯”)
- æ¨¡å‹æ£€æŸ¥ç‚¹ (æ¯50ä¸ªepochä¿å­˜)

### è¯„ä¼°æŒ‡æ ‡

- **Pearsonç›¸å…³ç³»æ•°**: è¡¡é‡æ³¢å½¢ç›¸å…³æ€§
- **å‡æ–¹è¯¯å·®(MSE)**: è¡¡é‡å¹…å€¼å‡†ç¡®æ€§
- **å®æ—¶å¯è§†åŒ–**: å›ºå®šæµ‹è¯•æ ·æœ¬çš„é‡å»ºæ•ˆæœ

## ğŸƒâ€â™‚ï¸ è¿è¡Œä¸åŒç‰ˆæœ¬

é¡¹ç›®åŒ…å«å¤šä¸ªè®­ç»ƒè„šæœ¬ç‰ˆæœ¬ï¼š

```bash
# åŸºç¡€ç‰ˆæœ¬
python train_v1.py

# åˆ†å¸ƒå¼ç‰ˆæœ¬
python train_v2_ddp.py

# å¸¦æ—¥å¿—ç‰ˆæœ¬
python train_v3_ddp_log.py

# SOTAç‰ˆæœ¬ (æ¨è)
python train_v10_sota.py

# æœ€æ–°æ”¹è¿›ç‰ˆæœ¬
python train_v16.py
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
HappyQuokka_system_for_EEG_Challenge/
â”œâ”€â”€ README.md                    # é¡¹ç›®è¯´æ˜
â”œâ”€â”€ train_v10_sota.py           # ä¸»è®­ç»ƒè„šæœ¬ (æ¨è)
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ FFT_block.py            # æ ¸å¿ƒæ¨¡å‹å®šä¹‰
â”‚   â””â”€â”€ SubLayers.py            # Transformerå­å±‚
â”œâ”€â”€ util/
â”‚   â”œâ”€â”€ dataset.py              # æ•°æ®åŠ è½½å™¨
â”‚   â”œâ”€â”€ cal_pearson.py          # æŸå¤±å‡½æ•°
â”‚   â””â”€â”€ utils.py                # å·¥å…·å‡½æ•°
â”œâ”€â”€ data/                       # æ•°æ®ç›®å½•
â”œâ”€â”€ test_results/               # è®­ç»ƒç»“æœ
â””â”€â”€ *.py                        # å…¶ä»–ç‰ˆæœ¬çš„è®­ç»ƒè„šæœ¬
```

## ğŸ¨ å¯è§†åŒ–åŠŸèƒ½

### æ¨¡å‹æ¶æ„å›¾
```bash
python model_architecture_diagram.py      # ç”ŸæˆåŸºç¡€æ¶æ„å›¾
python model_architecture_with_data.py    # ç”Ÿæˆå¸¦æ•°æ®ç»´åº¦çš„æ¶æ„å›¾
```

### è¯­éŸ³åŒ…ç»œè§£é‡Š
```bash
python explain_envelope.py                # ç”ŸæˆåŒ…ç»œæ¦‚å¿µè§£é‡Šå›¾
```

### è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–
```bash
tensorboard --logdir test_results/experiment_name/
```

## âš™ï¸ é«˜çº§åŠŸèƒ½

### åˆ†å¸ƒå¼è®­ç»ƒ

æ”¯æŒå¤šGPUå¹¶è¡Œè®­ç»ƒä»¥åŠ é€Ÿæ”¶æ•›ï¼š

```bash
# 4 GPUè®­ç»ƒ
CUDA_VISIBLE_DEVICES=0,1,2,3 python -m torch.distributed.launch \
    --nproc_per_node=4 train_v10_sota.py --use_ddp
```

### æ··åˆç²¾åº¦è®­ç»ƒ

å‡å°‘æ˜¾å­˜å ç”¨å¹¶åŠ é€Ÿè®­ç»ƒï¼š

```bash
python train_v10_sota.py --use_amp
```

### æ•°æ®å¢å¼º

- **å¤šçª—å£é‡‡æ ·**: æ¯ä¸ªæ ·æœ¬åœ¨ä¸€ä¸ªepochä¸­é‡‡æ ·å¤šä¸ªçª—å£
- **é¢„åŠ è½½æœºåˆ¶**: å°†æ•°æ®é¢„åŠ è½½åˆ°å†…å­˜å‡å°‘IOå¼€é”€

## ğŸ” è°ƒè¯•å’Œç›‘æ§

### æ¢¯åº¦ç›‘æ§
æ¨¡å‹ä¼šè‡ªåŠ¨è®°å½•ï¼š
- æ¯å±‚æ¢¯åº¦ç›´æ–¹å›¾
- æ¢¯åº¦èŒƒæ•°å˜åŒ–
- æƒé‡åˆ†å¸ƒæ¼”åŒ–

### æ€§èƒ½åˆ†æ
```bash
# æŸ¥çœ‹è®­ç»ƒé€Ÿåº¦
grep "é€Ÿåº¦" log.txt

# æŸ¥çœ‹æŸå¤±å˜åŒ–
grep "loss" log.txt
```

## ğŸŒŸ é¡¹ç›®ç‰¹è‰²

1. **ğŸ§  ç¥ç»ç§‘å­¦é©±åŠ¨**: åŸºäºå¤§è„‘å¬è§‰å¤„ç†æœºåˆ¶è®¾è®¡
2. **ğŸ—ï¸ æ··åˆæ¶æ„**: CNNç©ºé—´ç‰¹å¾ + Transformeræ—¶åºå»ºæ¨¡
3. **ğŸ‘¥ ä¸ªä½“åŒ–å»ºæ¨¡**: å—è¯•è€…ç‰¹å®šçš„å…¨å±€æ¡ä»¶å™¨
4. **âš¡ é«˜æ•ˆè®­ç»ƒ**: æ”¯æŒåˆ†å¸ƒå¼å’Œæ··åˆç²¾åº¦è®­ç»ƒ
5. **ğŸ“ˆ å®æ—¶ç›‘æ§**: ä¸°å¯Œçš„å¯è§†åŒ–å’Œæ—¥å¿—è®°å½•
6. **ğŸ”§ æ˜“äºæ‰©å±•**: æ¨¡å—åŒ–è®¾è®¡ï¼Œä¾¿äºæ”¹è¿›å’Œå®šåˆ¶

## ğŸ“š ç›¸å…³è®ºæ–‡å’Œå¼•ç”¨

```bibtex
@inproceedings{HappyQuokka2023,
  title={HappyQuokka: EEG-to-Speech Decoding System for ICASSP 2023 Challenge},
  author={Your Name},
  booktitle={ICASSP 2023 - IEEE International Conference on Acoustics, Speech and Signal Processing},
  year={2023}
}

@article{fastspeech,
  title={Fastspeech: Fast, robust and controllable text to speech},
  author={Ren, Yi and Ruan, Yangjun and Tan, Xu and Qin, Tao and Zhao, Sheng and Zhao, Zhou and Liu, Tie-Yan},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@data{eegdata_K3VSND_2023,
  author = {Bollens, Lies and Accou, Bernd and Van hamme, Hugo and Francart, Tom},
  publisher = {KU Leuven RDR},
  title = {{A Large Auditory EEG decoding dataset}},
  year = {2023},
  version = {V1},
  doi = {10.48804/K3VSND},
  url = {https://doi.org/10.48804/K3VSND}
}
```

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿æäº¤é—®é¢˜å’Œæ”¹è¿›å»ºè®®ï¼

1. Fork æœ¬é¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å¼€å¯Pull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäº MIT è®¸å¯è¯å¼€æº - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

## ğŸ”— ç›¸å…³é“¾æ¥

- **æŒ‘æˆ˜èµ›å®˜ç½‘**: [ICASSP 2023 Auditory EEG Challenge](https://github.com/exporl/auditory-eeg-challenge-2023-code)
- **æ•°æ®é›†**: [Large Auditory EEG Dataset](https://rdr.kuleuven.be/dataset.xhtml?persistentId=doi:10.48804/K3VSND)
- **FastSpeech**: [Original FastSpeech Implementation](https://github.com/xcmyz/FastSpeech)

## ğŸ“ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜è¯·æäº¤ Issue æˆ–è”ç³»é¡¹ç›®ç»´æŠ¤è€…ã€‚

---

<p align="center">
  Made with â¤ï¸ for neuroscience and speech technology
</p>