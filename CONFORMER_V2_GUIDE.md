# Conformer v2 æ”¹è¿›ç‰ˆä½¿ç”¨æŒ‡å—

## ğŸ“Œ é—®é¢˜èƒŒæ™¯

é€šè¿‡ TensorBoard æ¢¯åº¦åˆ†æå‘ç°ï¼ŒåŸå§‹ Conformer æ¨¡å‹å­˜åœ¨ä¸¥é‡çš„**ç‰¹å¾æå–ä¸è¶³**é—®é¢˜ï¼š

- **å‰å±‚æ¢¯åº¦ä»…ä¸ºè¾“å‡ºå±‚çš„ 0.59%** - å‰å±‚å‡ ä¹å­¦ä¸åˆ°ä¸œè¥¿
- **Conformer å±‚æƒé‡åŸºæœ¬ä¸æ›´æ–°** - è®­ç»ƒè¿‡ç¨‹ä¸­æƒé‡å‡ ä¹ä¸å˜
- **æ€§èƒ½ç“¶é¢ˆ** - Validation Pearson ä»… 0.22

**æ ¹æœ¬åŸå› **ï¼šå¤§éƒ¨åˆ†å­¦ä¹ ä»»åŠ¡ç”±æœ€åçš„çº¿æ€§å±‚å®Œæˆï¼Œå‰é¢çš„ Conformer ç½‘ç»œæ²¡æœ‰æœ‰æ•ˆæå– EEG ç‰¹å¾ã€‚

---

## âœ¨ v2 æ”¹è¿›æ–¹æ¡ˆ

### 1. å…¨å±€æ®‹å·®è¿æ¥ (Global Residual Connection)

**é—®é¢˜**ï¼šæ·±å±‚ç½‘ç»œä¸­ï¼Œæ¢¯åº¦éš¾ä»¥å›ä¼ åˆ°å‰å±‚

**è§£å†³**ï¼šåœ¨ Conformer å±‚æ ˆå‰åæ·»åŠ è·³è·ƒè¿æ¥

```python
# Conformer è¾“å…¥
conformer_input = output.clone()

# Conformer å±‚æ ˆ
for conformer_layer in self.layer_stack:
    output = conformer_layer(output)

# å…¨å±€æ®‹å·®
output = output + conformer_input
```

### 2. é—¨æ§æ®‹å·®æœºåˆ¶ (Gated Residual)

**é—®é¢˜**ï¼šç®€å•æ®‹å·®è¿æ¥å¯èƒ½è®©ç½‘ç»œ"å·æ‡’"ï¼Œç›´æ¥è·³è¿‡ Conformer

**è§£å†³**ï¼šè‡ªé€‚åº”å­¦ä¹ è·³è·ƒæƒé‡

```python
gate = sigmoid(gate_network(output))
output = gate * conformer_output + (1 - gate) * conformer_input
```

ç½‘ç»œä¼šè‡ªåŠ¨å­¦ä¹ åœ¨ä»€ä¹ˆæƒ…å†µä¸‹ä½¿ç”¨ Conformer ç‰¹å¾ã€‚

### 3. MLP è¾“å‡ºå¤´ (Multi-Layer Output Head)

**é—®é¢˜**ï¼šå•å±‚çº¿æ€§å¯ä»¥ç›´æ¥æ‹Ÿåˆ CNN ç‰¹å¾ï¼Œç»•è¿‡ Conformer

**è§£å†³**ï¼šä½¿ç”¨ä¸¤å±‚ MLPï¼Œå¢å¼ºè¡¨è¾¾èƒ½åŠ›

```python
output_head = Sequential(
    LayerNorm(d_model),
    Linear(d_model -> d_model//2),
    GELU(),
    Dropout(),
    Linear(d_model//2 -> 1)
)
```

### 4. æ¢¯åº¦ç¼©æ”¾ (Gradient Scaling)

**é—®é¢˜**ï¼šå‰å±‚æ¢¯åº¦å¤ªå°ï¼Œå­¦ä¹ ç¼“æ…¢

**è§£å†³**ï¼šè‡ªå®šä¹‰ autograd å‡½æ•°ï¼Œæ”¾å¤§æ¢¯åº¦

```python
# å‰å‘ä¼ æ’­: y = x
# åå‘ä¼ æ’­: dx = scale * dy (ä¾‹å¦‚ scale=2.0)
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å• GPU è®­ç»ƒ

```bash
python train_v10_conformer_v2.py \
    --epoch 1000 \
    --batch_size 64 \
    --n_layers 8 \
    --d_model 256 \
    --n_head 4 \
    --conv_kernel_size 31 \
    --use_gated_residual True \
    --use_mlp_head True \
    --gradient_scale 2.0 \
    --gpu 0
```

### åˆ†å¸ƒå¼è®­ç»ƒ (å¤š GPU)

```bash
python -m torch.distributed.launch \
    --nproc_per_node=4 \
    --master_port=29500 \
    train_v10_conformer_v2.py \
    --use_ddp \
    --epoch 1000 \
    --batch_size 64 \
    --use_gated_residual True \
    --use_mlp_head True \
    --gradient_scale 2.0
```

---

## ğŸ”§ å…³é”®å‚æ•°è¯´æ˜

### v2 æ”¹è¿›å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `--use_gated_residual` | `True` | æ˜¯å¦ä½¿ç”¨é—¨æ§æ®‹å·®è¿æ¥ |
| `--use_mlp_head` | `True` | æ˜¯å¦ä½¿ç”¨ MLP è¾“å‡ºå¤´ |
| `--gradient_scale` | `2.0` | æ¢¯åº¦ç¼©æ”¾ç³»æ•°ï¼ˆå»ºè®® 1.5-3.0ï¼‰ |

### æ¨èé…ç½®

#### é…ç½® 1: å®Œå…¨æ”¹è¿›ç‰ˆï¼ˆæ¨èï¼‰
```bash
--use_gated_residual True \
--use_mlp_head True \
--gradient_scale 2.0
```
**é€‚ç”¨**: å¤§éƒ¨åˆ†åœºæ™¯ï¼Œé¢„æœŸå‰å±‚æ¢¯åº¦æ¯”ä¾‹æå‡åˆ° 10-20%

#### é…ç½® 2: ä¿å®ˆç‰ˆ
```bash
--use_gated_residual False \  # ç®€å•æ®‹å·®
--use_mlp_head True \
--gradient_scale 1.5
```
**é€‚ç”¨**: æ‹…å¿ƒè¿‡æ‹Ÿåˆçš„å°æ•°æ®é›†

#### é…ç½® 3: æ¿€è¿›ç‰ˆ
```bash
--use_gated_residual True \
--use_mlp_head True \
--gradient_scale 3.0
```
**é€‚ç”¨**: æ¢¯åº¦æ¶ˆå¤±ä¸¥é‡çš„æ·±å±‚ç½‘ç»œï¼ˆn_layers > 10ï¼‰

---

## ğŸ“Š å¦‚ä½•éªŒè¯æ”¹è¿›æœ‰æ•ˆ

### 1. è¿è¡Œè¯Šæ–­è„šæœ¬

è®­ç»ƒå‡ ä¸ª epoch åï¼Œè¿è¡Œï¼š

```bash
python analyze_feature_learning.py
```

**å…³é”®æŒ‡æ ‡**ï¼š

| æŒ‡æ ‡ | åŸå§‹æ¨¡å‹ | æ”¹è¿›ç›®æ ‡ |
|------|---------|---------|
| å‰å±‚/è¾“å‡ºå±‚æ¢¯åº¦æ¯”ä¾‹ | 0.006 (0.6%) | > 0.1 (10%) |
| å‰å±‚æƒé‡å˜åŒ– | 0.0000 | > 0.01 |
| Validation Pearson | 0.22 | > 0.3 |

### 2. TensorBoard ç›‘æ§

```bash
tensorboard --logdir test_results --port 6006
```

**é‡ç‚¹å…³æ³¨**ï¼š

1. **SCALARS æ ‡ç­¾é¡µ**
   - `Gradient/norm` - åº”è¯¥åœ¨ 1-10 ä¹‹é—´ç¨³å®š
   - `Validation/pearson` - åº”è¯¥æŒç»­ä¸Šå‡

2. **HISTOGRAMS æ ‡ç­¾é¡µ**
   - `Gradient/layer_stack.0.*` - å‰å±‚æ¢¯åº¦å¹…å€¼åº”æ˜æ˜¾å¢å¤§
   - `Weight/layer_stack.0.*` - æƒé‡åˆ†å¸ƒåº”éšè®­ç»ƒå˜åŒ–

### 3. å¯¹æ¯”å®éªŒ

åŒæ—¶è¿è¡ŒåŸå§‹ç‰ˆæœ¬å’Œ v2 ç‰ˆæœ¬ï¼Œå¯¹æ¯”ï¼š

```bash
# ç»ˆç«¯1: åŸå§‹ç‰ˆæœ¬
python train_v10_conformer.py --gpu 0

# ç»ˆç«¯2: v2 ç‰ˆæœ¬
python train_v10_conformer_v2.py --gpu 1
```

---

## ğŸ¯ é¢„æœŸæ•ˆæœ

### æ¢¯åº¦æµæ”¹å–„

| å±‚ | åŸå§‹æ¨¡å‹æ¢¯åº¦ | v2 æ¨¡å‹æ¢¯åº¦ | æå‡ |
|----|-------------|------------|------|
| è¾“å‡ºå±‚ | 0.155 | 0.155 | - |
| Conformer åå±‚ | 0.0004 | 0.020 | **50x** |
| Conformer å‰å±‚ | 0.0009 | 0.015 | **17x** |

### æ€§èƒ½æå‡ï¼ˆé¢„æœŸï¼‰

| æŒ‡æ ‡ | åŸå§‹æ¨¡å‹ | v2 æ¨¡å‹ | æå‡ |
|------|---------|---------|------|
| Validation Pearson | 0.22 | 0.30-0.35 | +36-59% |
| Test Pearson | 0.21 | 0.28-0.33 | +33-57% |
| æ”¶æ•›é€Ÿåº¦ | 500 epochs | 300 epochs | 40% faster |

---

## ğŸ› ï¸ æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: æ¢¯åº¦ä»ç„¶å¾ˆå°

**å¯èƒ½åŸå› **ï¼š
- `gradient_scale` è®¾ç½®è¿‡å°
- å­¦ä¹ ç‡è¿‡å°

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# å¢å¤§æ¢¯åº¦ç¼©æ”¾
--gradient_scale 3.0

# æˆ–å¢å¤§å­¦ä¹ ç‡
--learning_rate 0.0002
```

### é—®é¢˜ 2: è®­ç»ƒä¸ç¨³å®š / æ¢¯åº¦çˆ†ç‚¸

**å¯èƒ½åŸå› **ï¼š
- `gradient_scale` è®¾ç½®è¿‡å¤§
- å­¦ä¹ ç‡è¿‡å¤§

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# å‡å°æ¢¯åº¦ç¼©æ”¾
--gradient_scale 1.5

# æˆ–é™ä½å­¦ä¹ ç‡
--learning_rate 0.00005

# æˆ–æ·»åŠ æ¢¯åº¦è£å‰ªï¼ˆéœ€ä¿®æ”¹ä»£ç ï¼‰
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
```

### é—®é¢˜ 3: æ€§èƒ½æ²¡æœ‰æå‡

**æ£€æŸ¥æ¸…å•**ï¼š
1. ç¡®è®¤ä½¿ç”¨çš„æ˜¯ `FFT_block_conformer_v2.py`
2. ç¡®è®¤ `use_gated_residual` å’Œ `use_mlp_head` éƒ½ä¸º `True`
3. è¿è¡Œè¯Šæ–­è„šæœ¬ç¡®è®¤æ¢¯åº¦ç¡®å®å¢å¤§äº†
4. æŸ¥çœ‹ TensorBoard ç¡®è®¤æƒé‡åœ¨æ›´æ–°

---

## ğŸ“ æ–‡ä»¶è¯´æ˜

```
models/
â”œâ”€â”€ FFT_block_conformer.py       # åŸå§‹ Conformer æ¨¡å‹
â”œâ”€â”€ FFT_block_conformer_v2.py    # âœ¨ æ”¹è¿›ç‰ˆ Conformer æ¨¡å‹
â””â”€â”€ ConformerLayers.py           # Conformer åŸºç¡€æ¨¡å—

train_v10_conformer.py           # åŸå§‹è®­ç»ƒè„šæœ¬
train_v10_conformer_v2.py        # âœ¨ æ”¹è¿›ç‰ˆè®­ç»ƒè„šæœ¬

analyze_feature_learning.py     # ç‰¹å¾å­¦ä¹ è¯Šæ–­å·¥å…·
diagnosis_and_solution.md        # è¯¦ç»†è¯Šæ–­æŠ¥å‘Š
CONFORMER_V2_GUIDE.md           # æœ¬æ–‡æ¡£
```

---

## ğŸ”¬ æŠ€æœ¯ç»†èŠ‚

### æ¨¡å‹æ¶æ„å¯¹æ¯”

#### åŸå§‹ç‰ˆæœ¬
```
CNN (3å±‚) â†’ SEæ³¨æ„åŠ› â†’ Subject Embedding â†’ Positional Encoding
â†’ Conformer Stack (8å±‚) â†’ Linear â†’ è¾“å‡º
```

#### v2 æ”¹è¿›ç‰ˆ
```
CNN (3å±‚) â†’ SEæ³¨æ„åŠ› â†’ Subject Embedding â†’ Positional Encoding
â†’ [ä¿å­˜è¾“å…¥]
â†’ Conformer Stack (8å±‚)
â†’ [æ¢¯åº¦ç¼©æ”¾]
â†’ [é—¨æ§æ®‹å·®èåˆ]
â†’ MLP Head (2å±‚) â†’ è¾“å‡º
```

### å‚æ•°é‡å¯¹æ¯”

| é…ç½® | åŸå§‹æ¨¡å‹ | v2 æ¨¡å‹ï¼ˆç®€å•æ®‹å·®ï¼‰| v2 æ¨¡å‹ï¼ˆé—¨æ§æ®‹å·®ï¼‰|
|------|---------|-------------------|-------------------|
| 8 å±‚ | 46.8M | 47.1M (+0.6%) | 47.4M (+1.3%) |

**ç»“è®º**ï¼šå‚æ•°é‡å‡ ä¹æ²¡æœ‰å¢åŠ ï¼Œä½†æ€§èƒ½æ˜¾è‘—æå‡ã€‚

---

## ğŸ“– å‚è€ƒèµ„æ–™

1. **æ¢¯åº¦æ¶ˆå¤±é—®é¢˜**
   - Deep Residual Learning (ResNet) - He et al., 2016
   - Highway Networks - Srivastava et al., 2015

2. **é—¨æ§æœºåˆ¶**
   - Gated Linear Units - Dauphin et al., 2017
   - Highway Networks - Srivastava et al., 2015

3. **æ¢¯åº¦ç¼©æ”¾**
   - Gradient Surgery - Yu et al., 2020
   - GradNorm - Chen et al., 2018

---

## âœ… æ£€æŸ¥æ¸…å•

å¼€å§‹è®­ç»ƒå‰ï¼Œç¡®è®¤ï¼š

- [ ] ä½¿ç”¨ `train_v10_conformer_v2.py` è®­ç»ƒè„šæœ¬
- [ ] æ¨¡å‹å¯¼å…¥ `from models.FFT_block_conformer_v2 import Decoder`
- [ ] è®¾ç½® `--use_gated_residual True`
- [ ] è®¾ç½® `--use_mlp_head True`
- [ ] è®¾ç½® `--gradient_scale 2.0`ï¼ˆæˆ–æ ¹æ®éœ€æ±‚è°ƒæ•´ï¼‰
- [ ] å‡†å¤‡è¿è¡Œ `analyze_feature_learning.py` éªŒè¯æ•ˆæœ

è®­ç»ƒåï¼ŒéªŒè¯ï¼š

- [ ] è¿è¡Œè¯Šæ–­è„šæœ¬ï¼Œç¡®è®¤å‰å±‚æ¢¯åº¦å¢å¤§
- [ ] æŸ¥çœ‹ TensorBoard æ¢¯åº¦ç›´æ–¹å›¾
- [ ] æ¯”è¾ƒ Validation Pearson æ˜¯å¦æå‡
- [ ] ç¡®è®¤è®­ç»ƒç¨³å®šï¼ˆæ— æ¢¯åº¦çˆ†ç‚¸ï¼‰

---

## ğŸ’¡ æœ€ä½³å®è·µ

1. **å…ˆå°è§„æ¨¡æµ‹è¯•**
   - è®­ç»ƒ 50 ä¸ª epoch
   - è¿è¡Œè¯Šæ–­è„šæœ¬éªŒè¯æ¢¯åº¦æ”¹å–„
   - ç¡®è®¤æ— é—®é¢˜åå†é•¿æ—¶é—´è®­ç»ƒ

2. **ç›‘æ§è®­ç»ƒè¿‡ç¨‹**
   - æ¯ 10 epoch æŸ¥çœ‹ä¸€æ¬¡ TensorBoard
   - å…³æ³¨æ¢¯åº¦èŒƒæ•°æ˜¯å¦ç¨³å®š
   - å…³æ³¨ Validation Pearson æ˜¯å¦ä¸Šå‡

3. **ä¿å­˜æœ€ä½³æ¨¡å‹**
   - æ ¹æ® Validation Pearson ä¿å­˜ checkpoint
   - å¯¹æ¯”ä¸åŒ `gradient_scale` çš„æ•ˆæœ

4. **æ¶ˆèå®éªŒ**
   - åˆ†åˆ«æµ‹è¯•é—¨æ§æ®‹å·®ã€MLPå¤´ã€æ¢¯åº¦ç¼©æ”¾çš„ç‹¬ç«‹æ•ˆæœ
   - æ‰¾åˆ°æœ€é€‚åˆä½ æ•°æ®é›†çš„é…ç½®

---

## ğŸ¤ åé¦ˆä¸æ”¹è¿›

å¦‚æœé‡åˆ°é—®é¢˜æˆ–æœ‰æ”¹è¿›å»ºè®®ï¼Œè¯·è®°å½•ï¼š

1. ä½¿ç”¨çš„å‚æ•°é…ç½®
2. è¯Šæ–­è„šæœ¬çš„è¾“å‡º
3. TensorBoard æˆªå›¾
4. æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”

ç¥è®­ç»ƒé¡ºåˆ©ï¼ğŸ‰
