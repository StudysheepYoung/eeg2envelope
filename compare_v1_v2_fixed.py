"""
ä¿®æ­£ç‰ˆï¼šå¯¹æ¯”åŸå§‹ç‰ˆæœ¬å’Œ v2 ç‰ˆæœ¬çš„æ¢¯åº¦æ”¹å–„æ•ˆæœ
"""
import os
import numpy as np
from tensorboard.backend.event_processing import event_accumulator

# ä¸¤ä¸ªæ¨¡å‹çš„æ—¥å¿—è·¯å¾„
v1_log_path = "/RAID5/projects/likeyang/happy/HappyQuokka_system_for_EEG_Challenge/test_results/conformer_nlayer8_dmodel256_nhead4_conv31_dist_20251121_172042"
v2_log_path = "/RAID5/projects/likeyang/happy/HappyQuokka_system_for_EEG_Challenge/test_results/conformer_v2_nlayer8_dmodel256_nhead4_gscale2.0_dist_20251122_114434"

print("=" * 80)
print("Conformer v1 vs v2 æ¢¯åº¦å¯¹æ¯”åˆ†æ (ä¿®æ­£ç‰ˆ)")
print("=" * 80)

# åŠ è½½ä¸¤ä¸ªæ¨¡å‹çš„æ•°æ®
ea_v1 = event_accumulator.EventAccumulator(v1_log_path)
ea_v1.Reload()

ea_v2 = event_accumulator.EventAccumulator(v2_log_path)
ea_v2.Reload()

print("\nã€æ ‡é‡æŒ‡æ ‡å¯¹æ¯”ã€‘")
print("=" * 80)

print(f"\n{'æŒ‡æ ‡':<30} {'v1 åŸå§‹ç‰ˆ':<15} {'v2 æ”¹è¿›ç‰ˆ':<15} {'å˜åŒ–':<15}")
print("-" * 80)

metrics = {
    'Train/loss_total': 'è®­ç»ƒæ€»æŸå¤±',
    'Train/loss_mse': 'è®­ç»ƒMSEæŸå¤±',
    'Train/loss_pearson': 'è®­ç»ƒPearsonæŸå¤±',
    'Gradient/norm': 'æ¢¯åº¦èŒƒæ•°',
    'Validation/loss': 'éªŒè¯æŸå¤±',
    'Validation/pearson': 'éªŒè¯Pearson',
    'Test/loss': 'æµ‹è¯•æŸå¤±',
    'Test/pearson': 'æµ‹è¯•Pearson'
}

results = {}
for metric, name in metrics.items():
    v1_events = ea_v1.Scalars(metric)
    v2_events = ea_v2.Scalars(metric)

    if len(v1_events) > 0 and len(v2_events) > 0:
        v1_val = v1_events[-1].value
        v2_val = v2_events[-1].value
        results[metric] = (v1_val, v2_val)

        # è®¡ç®—å˜åŒ–
        if 'loss' in metric.lower():
            change = (v1_val - v2_val) / abs(v1_val) * 100
            symbol = 'â†“' if change > 0 else 'â†‘'
        else:
            change = (v2_val - v1_val) / abs(v1_val) * 100
            symbol = 'â†‘' if change > 0 else 'â†“'

        change_str = f"{change:+.1f}% {symbol}"
        print(f"{metric:<30} {v1_val:<15.6f} {v2_val:<15.6f} {change_str:<15}")

# æ¢¯åº¦ç›´æ–¹å›¾åˆ†æ
print("\n" + "=" * 80)
print("ã€æ¢¯åº¦åˆ†å¸ƒå¯¹æ¯” - è¯¦ç»†åˆ†æã€‘")
print("=" * 80)

histograms_v1 = ea_v1.Tags().get('histograms', [])
histograms_v2 = ea_v2.Tags().get('histograms', [])

gradient_hists_v1 = [h for h in histograms_v1 if 'Gradient' in h]
gradient_hists_v2 = [h for h in histograms_v2 if 'Gradient' in h]

def get_gradient_magnitude(tag, ea):
    """è·å–æŒ‡å®šå±‚çš„æ¢¯åº¦å¹…å€¼"""
    events = ea.Histograms(tag)
    if len(events) > 0:
        latest = events[-1]
        hist_values = latest.histogram_value
        return max(abs(hist_values.min), abs(hist_values.max))
    return 0

# ç»Ÿè®¡å„å±‚æ¢¯åº¦
print("\n1. å‰å±‚ Conformer (layer_stack.0) æ¢¯åº¦å¯¹æ¯”:")
print("-" * 80)
print(f"{'æ¨¡å—':<50} {'v1':<12} {'v2':<12} {'æå‡':<10}")
print("-" * 80)

layer0_tags_v1 = [t for t in gradient_hists_v1 if 'layer_stack.0' in t]
layer0_tags_v2 = [t for t in gradient_hists_v2 if 'layer_stack.0' in t]

v1_layer0_grads = []
v2_layer0_grads = []

for tag_v1 in layer0_tags_v1:
    module_name = tag_v1.split('layer_stack.0.')[-1]
    tag_v2 = f"Gradient/layer_stack.0.{module_name}"

    if tag_v2 in gradient_hists_v2:
        grad_v1 = get_gradient_magnitude(tag_v1, ea_v1)
        grad_v2 = get_gradient_magnitude(tag_v2, ea_v2)

        v1_layer0_grads.append(grad_v1)
        v2_layer0_grads.append(grad_v2)

        improvement = grad_v2 / grad_v1 if grad_v1 > 0 else 0
        print(f"{module_name:<50} {grad_v1:<12.6f} {grad_v2:<12.6f} {improvement:>9.1f}x")

avg_v1_layer0 = np.mean(v1_layer0_grads) if v1_layer0_grads else 0
avg_v2_layer0 = np.mean(v2_layer0_grads) if v2_layer0_grads else 0

print("-" * 80)
print(f"{'å¹³å‡å€¼':<50} {avg_v1_layer0:<12.6f} {avg_v2_layer0:<12.6f} {avg_v2_layer0/avg_v1_layer0:>9.1f}x")

# åå±‚å¯¹æ¯”
print("\n2. åå±‚ Conformer (layer_stack.7) æ¢¯åº¦å¯¹æ¯”:")
print("-" * 80)

layer7_tags_v1 = [t for t in gradient_hists_v1 if 'layer_stack.7' in t]
layer7_tags_v2 = [t for t in gradient_hists_v2 if 'layer_stack.7' in t]

v1_layer7_grads = []
v2_layer7_grads = []

for tag_v1 in layer7_tags_v1[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
    module_name = tag_v1.split('layer_stack.7.')[-1]
    tag_v2 = f"Gradient/layer_stack.7.{module_name}"

    if tag_v2 in gradient_hists_v2:
        grad_v1 = get_gradient_magnitude(tag_v1, ea_v1)
        grad_v2 = get_gradient_magnitude(tag_v2, ea_v2)

        v1_layer7_grads.append(grad_v1)
        v2_layer7_grads.append(grad_v2)

avg_v1_layer7 = np.mean([get_gradient_magnitude(t, ea_v1) for t in layer7_tags_v1])
avg_v2_layer7 = np.mean([get_gradient_magnitude(t, ea_v2) for t in layer7_tags_v2])

print(f"å¹³å‡æ¢¯åº¦: v1={avg_v1_layer7:.6f}, v2={avg_v2_layer7:.6f}, æå‡={avg_v2_layer7/avg_v1_layer7:.1f}x")

# CNN å±‚å¯¹æ¯”
print("\n3. CNN ç‰¹å¾æå–å±‚ (conv1) æ¢¯åº¦å¯¹æ¯”:")
print("-" * 80)

conv1_tags = ['Gradient/conv1.weight', 'Gradient/conv1.bias']
for tag in conv1_tags:
    grad_v1 = get_gradient_magnitude(tag, ea_v1)
    grad_v2 = get_gradient_magnitude(tag, ea_v2)
    improvement = grad_v2 / grad_v1 if grad_v1 > 0 else 0
    print(f"{tag:<50} {grad_v1:<12.6f} {grad_v2:<12.6f} {improvement:>9.1f}x")

# æ¢¯åº¦èŒƒæ•°å¯¹æ¯”
print("\n" + "=" * 80)
print("ã€å…³é”®å‘ç°ã€‘")
print("=" * 80)

grad_norm_v1 = results.get('Gradient/norm', (0, 0))[0]
grad_norm_v2 = results.get('Gradient/norm', (0, 0))[1]
grad_norm_increase = (grad_norm_v2 - grad_norm_v1) / grad_norm_v1 * 100

print(f"\n1. å…¨å±€æ¢¯åº¦èŒƒæ•°:")
print(f"   v1: {grad_norm_v1:.4f}")
print(f"   v2: {grad_norm_v2:.4f}")
print(f"   æå‡: {grad_norm_increase:+.1f}%")

if grad_norm_increase > 50:
    print(f"   âœ… æ¢¯åº¦èŒƒæ•°æ˜¾è‘—å¢å¤§ï¼Œè¯´æ˜æ¨¡å‹æ•´ä½“å­¦ä¹ èƒ½åŠ›å¢å¼º")
else:
    print(f"   â†’ æ¢¯åº¦èŒƒæ•°ç•¥æœ‰å¢å¤§")

print(f"\n2. å‰å±‚æ¢¯åº¦æ”¹å–„:")
print(f"   layer_stack.0 å¹³å‡æ¢¯åº¦æå‡: {avg_v2_layer0/avg_v1_layer0:.1f}x")

if avg_v2_layer0/avg_v1_layer0 > 2:
    print(f"   âœ… å‰å±‚æ¢¯åº¦æ˜¾è‘—å¢å¼º (>{avg_v2_layer0/avg_v1_layer0:.0f}å€)ï¼Œç‰¹å¾æå–èƒ½åŠ›æå‡")
elif avg_v2_layer0/avg_v1_layer0 > 1.5:
    print(f"   âœ“ å‰å±‚æ¢¯åº¦æœ‰æ‰€å¢å¼º")
else:
    print(f"   â†’ å‰å±‚æ¢¯åº¦æ”¹å–„æœ‰é™")

val_pearson_v1 = results.get('Validation/pearson', (0, 0))[0]
val_pearson_v2 = results.get('Validation/pearson', (0, 0))[1]
pearson_change = (val_pearson_v2 - val_pearson_v1) / val_pearson_v1 * 100

print(f"\n3. æ€§èƒ½æŒ‡æ ‡:")
print(f"   Validation Pearson: {val_pearson_v1:.4f} â†’ {val_pearson_v2:.4f} ({pearson_change:+.1f}%)")

test_pearson_v1 = results.get('Test/pearson', (0, 0))[0]
test_pearson_v2 = results.get('Test/pearson', (0, 0))[1]
test_pearson_change = (test_pearson_v2 - test_pearson_v1) / test_pearson_v1 * 100

print(f"   Test Pearson: {test_pearson_v1:.4f} â†’ {test_pearson_v2:.4f} ({test_pearson_change:+.1f}%)")

# æ€»ç»“
print("\n" + "=" * 80)
print("ã€æ€»ä½“è¯„ä¼°ã€‘")
print("=" * 80)

print("\næ¶æ„æ”¹è¿›æ•ˆæœ:")
score = 0

if avg_v2_layer0/avg_v1_layer0 > 2:
    print("  âœ… å‰å±‚æ¢¯åº¦æå‡æ˜¾è‘—")
    score += 3
elif avg_v2_layer0/avg_v1_layer0 > 1.5:
    print("  âœ“ å‰å±‚æ¢¯åº¦æœ‰æ‰€æå‡")
    score += 2
else:
    print("  â†’ å‰å±‚æ¢¯åº¦æå‡æœ‰é™")
    score += 1

if grad_norm_increase > 50:
    print("  âœ… å…¨å±€æ¢¯åº¦èŒƒæ•°æ˜¾è‘—å¢å¼º")
    score += 2
elif grad_norm_increase > 20:
    print("  âœ“ å…¨å±€æ¢¯åº¦èŒƒæ•°æœ‰æ‰€å¢å¼º")
    score += 1

if test_pearson_change > 2:
    print("  âœ… æµ‹è¯•æ€§èƒ½æå‡")
    score += 2
elif test_pearson_change > 0:
    print("  âœ“ æµ‹è¯•æ€§èƒ½ç•¥æœ‰æå‡")
    score += 1
else:
    print("  â†’ æµ‹è¯•æ€§èƒ½æ— æ˜æ˜¾æå‡")

print(f"\næ€»åˆ†: {score}/7")

if score >= 6:
    print("ğŸ‰ æ”¹è¿›æ•ˆæœä¼˜ç§€ï¼v2 æ¶æ„æ˜æ˜¾ä¼˜äºåŸå§‹ç‰ˆæœ¬")
elif score >= 4:
    print("âœ“ æ”¹è¿›æœ‰æ•ˆï¼Œv2 æ¶æ„åœ¨æ¢¯åº¦å’Œæ€§èƒ½ä¸Šéƒ½æœ‰æå‡")
else:
    print("â†’ æ”¹è¿›æ•ˆæœæœ‰é™ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´è¶…å‚æ•°")

print("\nå»ºè®®:")
if avg_v2_layer0/avg_v1_layer0 < 3:
    print("  - å¯ä»¥å°è¯•å¢å¤§ gradient_scale (å¦‚ 3.0 æˆ– 4.0)")
if test_pearson_change < 5:
    print("  - è®­ç»ƒæ›´å¤š epochsï¼Œè§‚å¯Ÿé•¿æœŸæ•ˆæœ")
    print("  - æ£€æŸ¥æŸå¤±å‡½æ•°æƒé‡ lambda")

print("\n" + "=" * 80)
